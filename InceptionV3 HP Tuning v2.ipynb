{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "067c4865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf928d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic convolutional neural network\n",
    "import keras_tuner as kt\n",
    "from keras_tuner import BayesianOptimization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "import os, numpy as np, time\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49daa940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hms(start, end):\n",
    "    seconds = end-start\n",
    "    m, s = divmod(seconds, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return h,m,s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd5329b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hp):\n",
    "    \"\"\"\n",
    "    Compiles a model integrated with pretrained layers\n",
    "    \n",
    "    \"\"\"\n",
    "    learning_rate = hp.Choice('learning_rate', values = [0.000001, 0.00001, 0.0001], default = 0.000001)\n",
    "    dropout_rate = hp.Float('dropout', 0.2, 0.8, step=0.1)\n",
    "    neurons = hp.Choice('neurons', values = [256, 512, 1024, 2048], default = 256)\n",
    "    dense_layers = hp.Int('dense_layers', 0, 2, default = 0)\n",
    "    pooling = hp.Choice(\"global_pooling\", [\"flatten\", \"avg\"], default = 'flatten')\n",
    "        \n",
    "    # Pretrained convolutional layers are loaded using the Imagenet weights.\n",
    "    # Include_top is set to False, in order to exclude the model's fully-connected layers.\n",
    "    conv_base = InceptionV3(include_top=False,\n",
    "                     weights='imagenet', \n",
    "                     input_shape=(224, 224, 3))\n",
    "    \n",
    "    # Layers in the convolutional base are switched from trainable to non-trainable\n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Create a new 'top' of the model (i.e. fully-connected layers).\n",
    "    # This is 'bootstrapping' a new top_model onto the pretrained layers.\n",
    "    top_model = conv_base.output\n",
    "    \n",
    "    # Choose top model pooling layer.\n",
    "    if pooling == \"avg\":\n",
    "        top_model = GlobalAveragePooling2D()(top_model)\n",
    "        for dl in range(dense_layers):\n",
    "            top_model = Dense(neurons, activation='relu')(top_model)\n",
    "            top_model = Dropout(dropout_rate)(top_model)\n",
    "    else:\n",
    "        top_model = Flatten(name=\"flatten\")(top_model)\n",
    "        for dl in range(dense_layers):\n",
    "            top_model = Dense(neurons, activation='relu')(top_model)\n",
    "            top_model = Dropout(dropout_rate)(top_model)\n",
    "    \n",
    "    # Add final softmax layer for predictions\n",
    "    output_layer = Dense(5, activation='softmax')(top_model)\n",
    "    \n",
    "    # Group the convolutional base and new fully-connected layers into a Model object.\n",
    "    model = Model(inputs=conv_base.input, outputs=output_layer)\n",
    "\n",
    "    # Compiles the model for training.\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                                 loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f12ca8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 35 Complete [00h 03m 27s]\n",
      "val_accuracy: 0.7736111283302307\n",
      "\n",
      "Best val_accuracy So Far: 0.7972221970558167\n",
      "Total elapsed time: 02h 17m 34s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "{'learning_rate': 0.0001, 'dropout': 0.30000000000000004, 'neurons': 2048, 'dense_layers': 0, 'global_pooling': 'flatten'}\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 111, 111, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 111, 111, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 111, 111, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 109, 109, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 109, 109, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 109, 109, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 109, 109, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 109, 109, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 109, 109, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 54, 54, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 54, 54, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 54, 54, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 52, 52, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 52, 52, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 52, 52, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 25, 25, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 25, 25, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 25, 25, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 25, 25, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 25, 25, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 25, 25, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 25, 25, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 25, 25, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 25, 25, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 25, 25, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 25, 25, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 25, 25, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 25, 25, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 25, 25, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 25, 25, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 25, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 25, 25, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 25, 25, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 25, 25, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 25, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 25, 25, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 25, 25, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 25, 25, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, 25, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 25, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 25, 25, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 25, 25, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 25, 25, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 25, 25, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 25, 25, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 25, 25, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 25, 25, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 25, 25, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 25, 25, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 25, 25, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 25, 25, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 25, 25, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 25, 25, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 25, 25, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 25, 25, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 25, 25, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 25, 25, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 12, 12, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 12, 12, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 12, 12, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 12, 12, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 12, 12, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 12, 12, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 12, 12, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 12, 12, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 12, 12, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 12, 12, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 12, 12, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 12, 12, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 12, 12, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 12, 12, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 12, 12, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 12, 12, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 12, 12, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 12, 12, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 12, 12, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 12, 12, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 12, 12, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 12, 12, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 12, 12, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 12, 12, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 12, 12, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 12, 12, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 12, 12, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 12, 12, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 12, 12, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 12, 12, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 12, 12, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 12, 12, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 12, 12, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 12, 12, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 12, 12, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 12, 12, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 12, 12, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 12, 12, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 12, 12, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 12, 12, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 12, 12, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 12, 12, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 12, 12, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 12, 12, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 12, 12, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 12, 12, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 12, 12, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 12, 12, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 5, 5, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 5, 5, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 5, 5, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 5, 5, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 5, 5, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 5, 5, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 5, 5, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 5, 5, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 5, 5, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 5, 5, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 5, 5, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 5, 5, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 5, 5, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 5, 5, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 5, 5, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 5, 5, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 5, 5, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 5, 5, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 5, 5, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 5, 5, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 5, 5, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 5, 5, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 5, 5, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 5, 5, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 5, 5, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 5, 5, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 5, 5, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 5, 5, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 5, 5, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 51200)        0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 5)            256005      flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 22,058,789\n",
      "Trainable params: 256,005\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Results summary\n",
      "Results in hp_models\\InceptionV3\n",
      "Showing 35 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.30000000000000004\n",
      "neurons: 2048\n",
      "dense_layers: 0\n",
      "global_pooling: flatten\n",
      "Score: 0.7972221970558167\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.4000000000000001\n",
      "neurons: 2048\n",
      "dense_layers: 1\n",
      "global_pooling: flatten\n",
      "Score: 0.793055534362793\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.30000000000000004\n",
      "neurons: 2048\n",
      "dense_layers: 0\n",
      "global_pooling: flatten\n",
      "Score: 0.7902777791023254\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.6000000000000001\n",
      "neurons: 1024\n",
      "dense_layers: 1\n",
      "global_pooling: flatten\n",
      "Score: 0.7875000238418579\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 2048\n",
      "dense_layers: 1\n",
      "global_pooling: flatten\n",
      "Score: 0.7861111164093018\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.8000000000000003\n",
      "neurons: 2048\n",
      "dense_layers: 0\n",
      "global_pooling: flatten\n",
      "Score: 0.7819444537162781\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.30000000000000004\n",
      "neurons: 2048\n",
      "dense_layers: 0\n",
      "global_pooling: flatten\n",
      "Score: 0.7819444537162781\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 2048\n",
      "dense_layers: 1\n",
      "global_pooling: avg\n",
      "Score: 0.7805555462837219\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.5000000000000001\n",
      "neurons: 256\n",
      "dense_layers: 0\n",
      "global_pooling: flatten\n",
      "Score: 0.7777777910232544\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 2048\n",
      "dense_layers: 2\n",
      "global_pooling: avg\n",
      "Score: 0.7777777910232544\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 256\n",
      "dense_layers: 1\n",
      "global_pooling: avg\n",
      "Score: 0.7763888835906982\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.30000000000000004\n",
      "neurons: 2048\n",
      "dense_layers: 0\n",
      "global_pooling: flatten\n",
      "Score: 0.7736111283302307\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 512\n",
      "dense_layers: 2\n",
      "global_pooling: avg\n",
      "Score: 0.7680555582046509\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.4000000000000001\n",
      "neurons: 1024\n",
      "dense_layers: 1\n",
      "global_pooling: avg\n",
      "Score: 0.7652778029441833\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.30000000000000004\n",
      "neurons: 2048\n",
      "dense_layers: 0\n",
      "global_pooling: flatten\n",
      "Score: 0.7652778029441833\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 256\n",
      "dense_layers: 0\n",
      "global_pooling: flatten\n",
      "Score: 0.7638888955116272\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 2048\n",
      "dense_layers: 0\n",
      "global_pooling: flatten\n",
      "Score: 0.7638888955116272\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.30000000000000004\n",
      "neurons: 2048\n",
      "dense_layers: 0\n",
      "global_pooling: flatten\n",
      "Score: 0.7597222328186035\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.5000000000000001\n",
      "neurons: 2048\n",
      "dense_layers: 0\n",
      "global_pooling: flatten\n",
      "Score: 0.7583333253860474\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.30000000000000004\n",
      "neurons: 2048\n",
      "dense_layers: 0\n",
      "global_pooling: flatten\n",
      "Score: 0.7541666626930237\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.7000000000000002\n",
      "neurons: 2048\n",
      "dense_layers: 2\n",
      "global_pooling: avg\n",
      "Score: 0.7513889074325562\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.8000000000000003\n",
      "neurons: 2048\n",
      "dense_layers: 0\n",
      "global_pooling: avg\n",
      "Score: 0.75\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.30000000000000004\n",
      "neurons: 1024\n",
      "dense_layers: 0\n",
      "global_pooling: flatten\n",
      "Score: 0.7486110925674438\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 256\n",
      "dense_layers: 2\n",
      "global_pooling: flatten\n",
      "Score: 0.7472222447395325\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 2048\n",
      "dense_layers: 2\n",
      "global_pooling: flatten\n",
      "Score: 0.7430555820465088\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.30000000000000004\n",
      "neurons: 2048\n",
      "dense_layers: 0\n",
      "global_pooling: flatten\n",
      "Score: 0.7430555820465088\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.8000000000000003\n",
      "neurons: 256\n",
      "dense_layers: 1\n",
      "global_pooling: avg\n",
      "Score: 0.7416666746139526\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.8000000000000003\n",
      "neurons: 256\n",
      "dense_layers: 0\n",
      "global_pooling: flatten\n",
      "Score: 0.7361111044883728\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.8000000000000003\n",
      "neurons: 2048\n",
      "dense_layers: 2\n",
      "global_pooling: flatten\n",
      "Score: 0.7361111044883728\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.30000000000000004\n",
      "neurons: 2048\n",
      "dense_layers: 0\n",
      "global_pooling: flatten\n",
      "Score: 0.7347221970558167\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.30000000000000004\n",
      "neurons: 2048\n",
      "dense_layers: 0\n",
      "global_pooling: flatten\n",
      "Score: 0.7347221970558167\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 1e-05\n",
      "dropout: 0.5000000000000001\n",
      "neurons: 512\n",
      "dense_layers: 1\n",
      "global_pooling: avg\n",
      "Score: 0.7319444417953491\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 2048\n",
      "dense_layers: 0\n",
      "global_pooling: flatten\n",
      "Score: 0.7277777791023254\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 1e-06\n",
      "dropout: 0.8000000000000003\n",
      "neurons: 256\n",
      "dense_layers: 1\n",
      "global_pooling: flatten\n",
      "Score: 0.6625000238418579\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 1e-06\n",
      "dropout: 0.2\n",
      "neurons: 2048\n",
      "dense_layers: 0\n",
      "global_pooling: avg\n",
      "Score: 0.23194444179534912\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "31/31 [==============================] - 18s 372ms/step - loss: 1.0718 - accuracy: 0.6199 - val_loss: 1.0933 - val_accuracy: 0.6097\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.09328, saving model to weights\\InceptionV3.hp.weights.hdf5\n",
      "Epoch 2/50\n",
      "31/31 [==============================] - 12s 298ms/step - loss: 0.4623 - accuracy: 0.8353 - val_loss: 0.9091 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.09328 to 0.90906, saving model to weights\\InceptionV3.hp.weights.hdf5\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - 11s 298ms/step - loss: 0.3670 - accuracy: 0.8730 - val_loss: 0.8314 - val_accuracy: 0.7097\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.90906 to 0.83138, saving model to weights\\InceptionV3.hp.weights.hdf5\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - 12s 298ms/step - loss: 0.3378 - accuracy: 0.8772 - val_loss: 0.8715 - val_accuracy: 0.6986\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.83138\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - 12s 297ms/step - loss: 0.2825 - accuracy: 0.9059 - val_loss: 0.8138 - val_accuracy: 0.7194\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.83138 to 0.81380, saving model to weights\\InceptionV3.hp.weights.hdf5\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - 12s 302ms/step - loss: 0.2830 - accuracy: 0.9042 - val_loss: 0.8090 - val_accuracy: 0.7111\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.81380 to 0.80897, saving model to weights\\InceptionV3.hp.weights.hdf5\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - 12s 297ms/step - loss: 0.2689 - accuracy: 0.9074 - val_loss: 0.7947 - val_accuracy: 0.7264\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.80897 to 0.79472, saving model to weights\\InceptionV3.hp.weights.hdf5\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - 12s 299ms/step - loss: 0.2485 - accuracy: 0.9154 - val_loss: 0.7989 - val_accuracy: 0.7222\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.79472\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - 12s 300ms/step - loss: 0.2151 - accuracy: 0.9284 - val_loss: 0.8076 - val_accuracy: 0.7347\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.79472\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - 12s 300ms/step - loss: 0.2205 - accuracy: 0.9213 - val_loss: 0.8058 - val_accuracy: 0.7306\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.79472\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - 12s 302ms/step - loss: 0.2040 - accuracy: 0.9270 - val_loss: 0.7275 - val_accuracy: 0.7417\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.79472 to 0.72754, saving model to weights\\InceptionV3.hp.weights.hdf5\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - 12s 298ms/step - loss: 0.1856 - accuracy: 0.9358 - val_loss: 0.8019 - val_accuracy: 0.7417\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.72754\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - 12s 297ms/step - loss: 0.2052 - accuracy: 0.9243 - val_loss: 0.7575 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.72754\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - 12s 298ms/step - loss: 0.1878 - accuracy: 0.9336 - val_loss: 0.7438 - val_accuracy: 0.7528\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.72754\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - 12s 297ms/step - loss: 0.1968 - accuracy: 0.9321 - val_loss: 0.8356 - val_accuracy: 0.7125\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.72754\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - 12s 304ms/step - loss: 0.1754 - accuracy: 0.9375 - val_loss: 0.9069 - val_accuracy: 0.6792\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.72754\n",
      "Epoch 17/50\n",
      "31/31 [==============================] - 12s 299ms/step - loss: 0.1845 - accuracy: 0.9400 - val_loss: 0.7452 - val_accuracy: 0.7681\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.72754\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - 12s 300ms/step - loss: 0.1637 - accuracy: 0.9426 - val_loss: 0.7973 - val_accuracy: 0.7472\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.72754\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - 12s 299ms/step - loss: 0.1701 - accuracy: 0.9424 - val_loss: 0.7373 - val_accuracy: 0.7639\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.72754\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - 12s 300ms/step - loss: 0.1471 - accuracy: 0.9490 - val_loss: 0.8127 - val_accuracy: 0.7306\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.72754\n",
      "Epoch 21/50\n",
      "31/31 [==============================] - 12s 299ms/step - loss: 0.1554 - accuracy: 0.9444 - val_loss: 0.7497 - val_accuracy: 0.7667\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.72754\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - 12s 297ms/step - loss: 0.1506 - accuracy: 0.9500 - val_loss: 0.7397 - val_accuracy: 0.7542\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.72754\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - 12s 303ms/step - loss: 0.1478 - accuracy: 0.9480 - val_loss: 0.7612 - val_accuracy: 0.7528\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.72754\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - 12s 299ms/step - loss: 0.1462 - accuracy: 0.9493 - val_loss: 0.7265 - val_accuracy: 0.7611\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.72754 to 0.72649, saving model to weights\\InceptionV3.hp.weights.hdf5\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - 12s 299ms/step - loss: 0.1437 - accuracy: 0.9507 - val_loss: 0.6975 - val_accuracy: 0.7611\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.72649 to 0.69745, saving model to weights\\InceptionV3.hp.weights.hdf5\n",
      "Epoch 26/50\n",
      "31/31 [==============================] - 12s 299ms/step - loss: 0.1586 - accuracy: 0.9446 - val_loss: 0.8087 - val_accuracy: 0.7556\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.69745\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - 12s 299ms/step - loss: 0.1487 - accuracy: 0.9500 - val_loss: 0.7503 - val_accuracy: 0.7625\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.69745\n",
      "Epoch 28/50\n",
      "31/31 [==============================] - 12s 302ms/step - loss: 0.1412 - accuracy: 0.9461 - val_loss: 0.9050 - val_accuracy: 0.7278\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.69745\n",
      "Epoch 29/50\n",
      "31/31 [==============================] - 12s 300ms/step - loss: 0.1491 - accuracy: 0.9490 - val_loss: 0.8090 - val_accuracy: 0.7486\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.69745\n",
      "Epoch 30/50\n",
      "31/31 [==============================] - 12s 298ms/step - loss: 0.1402 - accuracy: 0.9495 - val_loss: 0.8758 - val_accuracy: 0.7514\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.69745\n",
      "Epoch 31/50\n",
      "31/31 [==============================] - 12s 298ms/step - loss: 0.1300 - accuracy: 0.9578 - val_loss: 0.7780 - val_accuracy: 0.7653\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.69745\n",
      "Epoch 32/50\n",
      "31/31 [==============================] - 12s 300ms/step - loss: 0.1381 - accuracy: 0.9525 - val_loss: 0.6251 - val_accuracy: 0.7889\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.69745 to 0.62513, saving model to weights\\InceptionV3.hp.weights.hdf5\n",
      "Epoch 33/50\n",
      "31/31 [==============================] - 12s 300ms/step - loss: 0.1368 - accuracy: 0.9500 - val_loss: 0.7689 - val_accuracy: 0.7694\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.62513\n",
      "Epoch 34/50\n",
      "31/31 [==============================] - 12s 297ms/step - loss: 0.1536 - accuracy: 0.9414 - val_loss: 0.8362 - val_accuracy: 0.7375\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.62513\n",
      "Epoch 35/50\n",
      "31/31 [==============================] - 12s 298ms/step - loss: 0.1288 - accuracy: 0.9525 - val_loss: 0.7158 - val_accuracy: 0.7736\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.62513\n",
      "Epoch 36/50\n",
      "31/31 [==============================] - 12s 298ms/step - loss: 0.1413 - accuracy: 0.9490 - val_loss: 0.7638 - val_accuracy: 0.7625\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.62513\n",
      "Epoch 37/50\n",
      "31/31 [==============================] - 12s 297ms/step - loss: 0.1149 - accuracy: 0.9605 - val_loss: 0.7345 - val_accuracy: 0.7778\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.62513\n",
      "Epoch 38/50\n",
      "31/31 [==============================] - 12s 299ms/step - loss: 0.1172 - accuracy: 0.9596 - val_loss: 0.7478 - val_accuracy: 0.7722\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.62513\n",
      "Epoch 39/50\n",
      "31/31 [==============================] - 12s 300ms/step - loss: 0.1344 - accuracy: 0.9525 - val_loss: 0.7086 - val_accuracy: 0.7750\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.62513\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 12s 298ms/step - loss: 0.1206 - accuracy: 0.9591 - val_loss: 0.8442 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.62513\n",
      "Epoch 41/50\n",
      "31/31 [==============================] - 12s 300ms/step - loss: 0.1254 - accuracy: 0.9561 - val_loss: 0.9257 - val_accuracy: 0.7403\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.62513\n",
      "Epoch 42/50\n",
      "31/31 [==============================] - 12s 297ms/step - loss: 0.1352 - accuracy: 0.9512 - val_loss: 0.7202 - val_accuracy: 0.7694\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.62513\n",
      "Epoch 43/50\n",
      "31/31 [==============================] - 12s 300ms/step - loss: 0.1140 - accuracy: 0.9615 - val_loss: 0.7245 - val_accuracy: 0.7667\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.62513\n",
      "Epoch 44/50\n",
      "31/31 [==============================] - 12s 303ms/step - loss: 0.1387 - accuracy: 0.9515 - val_loss: 0.8623 - val_accuracy: 0.7403\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.62513\n",
      "Epoch 45/50\n",
      "31/31 [==============================] - 12s 301ms/step - loss: 0.1161 - accuracy: 0.9566 - val_loss: 0.7872 - val_accuracy: 0.7556\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.62513\n",
      "Epoch 46/50\n",
      "31/31 [==============================] - 12s 298ms/step - loss: 0.1292 - accuracy: 0.9549 - val_loss: 0.8104 - val_accuracy: 0.7708\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.62513\n",
      "Epoch 47/50\n",
      "31/31 [==============================] - 12s 306ms/step - loss: 0.1310 - accuracy: 0.9566 - val_loss: 0.7095 - val_accuracy: 0.7986\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.62513\n",
      "Epoch 48/50\n",
      "31/31 [==============================] - 12s 300ms/step - loss: 0.1303 - accuracy: 0.9569 - val_loss: 0.7517 - val_accuracy: 0.7778\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.62513\n",
      "Epoch 49/50\n",
      "31/31 [==============================] - 12s 299ms/step - loss: 0.1157 - accuracy: 0.9596 - val_loss: 0.8587 - val_accuracy: 0.7472\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.62513\n",
      "Epoch 50/50\n",
      "31/31 [==============================] - 12s 298ms/step - loss: 0.1231 - accuracy: 0.9566 - val_loss: 0.7164 - val_accuracy: 0.7903\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.62513\n",
      "Best InceptionV3 Model Accuracy: 94.42%\n",
      "Average prediction time per image: 0.025315619309743246 seconds\n",
      "\n",
      "Total runtime is 2 hours, 28 minutes, 38.3 seconds\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = 'cropped_resized_imgs/train'\n",
    "test_data_dir = 'cropped_resized_imgs/test'\n",
    "class_subset = sorted(os.listdir(train_data_dir))\n",
    "\n",
    "img_size = 224\n",
    "BATCH_SIZE = 128\n",
    "totalstart = time.time()\n",
    "modelName = 'InceptionV3'\n",
    "filename = 'InceptionV3_HP_Tuning_Results.txt'\n",
    "\n",
    "# create image generators with data augmentation\n",
    "train_generator = ImageDataGenerator(\n",
    "    width_shift_range=0.5,       # shift the width of the image 50%\n",
    "    rotation_range=90,           # random rotation by 90 degrees\n",
    "    horizontal_flip=True,        # 180 degree flip horizontally\n",
    "    vertical_flip=True,          # 180 degree flip vertically\n",
    "    validation_split=0.15,       # 15% of the data will be used for validation at end of each epoch\n",
    "    preprocessing_function=preprocess_input # preprocessing\n",
    ")\n",
    "\n",
    "traingen = train_generator.flow_from_directory(train_data_dir,\n",
    "                                                target_size=(img_size, img_size),\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                class_mode='categorical',\n",
    "                                                classes=class_subset,\n",
    "                                                subset='training',\n",
    "                                                shuffle=True,\n",
    "                                                seed=55)\n",
    "\n",
    "validgen = train_generator.flow_from_directory(train_data_dir,\n",
    "                                                target_size=(img_size, img_size),\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                class_mode='categorical',\n",
    "                                                classes=class_subset,\n",
    "                                                subset='validation',\n",
    "                                                shuffle=True,\n",
    "                                                seed=55)\n",
    "\n",
    "test_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "testgen = test_generator.flow_from_directory(test_data_dir,\n",
    "                                             target_size=(img_size, img_size),\n",
    "                                             batch_size=1,\n",
    "                                             class_mode=None,\n",
    "                                             shuffle=False,\n",
    "                                             seed=55)\n",
    "# set model run values\n",
    "n_epochs = 50\n",
    "max_trial_epochs = 40\n",
    "max_trials = 35\n",
    "n_steps = traingen.samples / BATCH_SIZE\n",
    "n_val_steps = validgen.samples / BATCH_SIZE\n",
    "\n",
    "tuner = BayesianOptimization(create_model,\n",
    "                objective = 'val_accuracy',\n",
    "                max_trials = max_trials,\n",
    "                directory = 'hp_models',\n",
    "                project_name = modelName,\n",
    "                overwrite = True,\n",
    "                seed=55)\n",
    "\n",
    "# Early Stopping\n",
    "tuner_early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           patience=5,\n",
    "                           restore_best_weights=True,\n",
    "                           mode='min')\n",
    "\n",
    "tuner.search(traingen,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            epochs=max_trial_epochs,\n",
    "            validation_data=validgen,\n",
    "            steps_per_epoch=n_steps,\n",
    "            validation_steps=n_val_steps,\n",
    "            callbacks=[tuner_early_stop],\n",
    "            workers=16,\n",
    "            verbose=1)\n",
    "\n",
    "# print and save tuner results\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "print(best_hp.values)\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)\n",
    "print(best_model[0].summary())\n",
    "\n",
    "print(tuner.results_summary(num_trials=max_trials))\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "    f.write('Best hyperparameters: {}\\n\\nBest Model Summary\\n'.format(best_hp.values))\n",
    "    best_model[0].summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "\n",
    "# ************************************************************************************************************\n",
    "# train full model with hyperparameters\n",
    "\n",
    "# ModelCheckpoint callback - save best weights\n",
    "tl_checkpoint_1 = ModelCheckpoint(filepath='weights/{}.hp.weights.hdf5'.format(modelName),\n",
    "                                  save_best_only=True,\n",
    "                                  verbose=1)\n",
    "\n",
    "# load and train model from hyperparameters\n",
    "bestTunedModel = tuner.hypermodel.build(best_hp)\n",
    "history = bestTunedModel.fit(traingen,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=n_epochs,\n",
    "                    validation_data=validgen,\n",
    "                    steps_per_epoch=n_steps,\n",
    "                    validation_steps=n_val_steps,\n",
    "                    callbacks=[tl_checkpoint_1],\n",
    "                    workers=16,\n",
    "                    verbose=1)\n",
    "\n",
    "# load model weights\n",
    "bestTunedModel.load_weights('weights/{}.hp.weights.hdf5'.format(modelName)) # initialize the best trained weights\n",
    "# get labels\n",
    "labels = traingen.class_indices\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "\n",
    "# Generate predictions\n",
    "testgen.reset()\n",
    "predstart = time.time()\n",
    "preds = bestTunedModel.predict(testgen)\n",
    "pred_classes = np.argmax(preds, axis=1)\n",
    "true_classes = testgen.classes\n",
    "acc = accuracy_score(true_classes, pred_classes)\n",
    "predend = time.time()\n",
    "avgPredictionTime = (predend - predstart)/1200\n",
    "\n",
    "print(\"Best {} Model Accuracy: {:.2f}%\".format(modelName, acc * 100))\n",
    "\n",
    "# save history object to disk\n",
    "with open('modelrun_history/{}.hp.history'.format(modelName), 'wb') as histfile:\n",
    "    pickle.dump(history.history, histfile)\n",
    "\n",
    "# save model accuracy to file\n",
    "with open(filename, 'a') as f:\n",
    "    f.write(\"{} Model Accuracy: {:.2f}%\\n\".format(modelName, acc * 100))\n",
    "    f.write(\"Average prediction time per image: {} seconds\\n\".format(avgPredictionTime))\n",
    "\n",
    "# total modeling time\n",
    "totalEnd = time.time()\n",
    "totalT=hms(totalstart, totalEnd)\n",
    "print(\"Average prediction time per image: {} seconds\\n\".format(avgPredictionTime))\n",
    "print('Total runtime is {:.0f} hours, {:.0f} minutes, {:.1f} seconds'.format(totalT[0],totalT[1],totalT[2]))\n",
    "with open(filename, 'a') as f:\n",
    "    f.write('Total runtime is {:.0f} hours, {:.0f} minutes, {:.1f} seconds'.format(totalT[0],totalT[1],totalT[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b8d9380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x28b38977bb0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training/validation accuracy and loss\n",
    "plt.figure(figsize=(12, 6)) # figsize(width, height) in inches, dpi=100\n",
    "# plot accuracy\n",
    "plt.subplot(1, 2, 1) # (rows, cols, index)\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\", \"Validation Accuracy\"])\n",
    "\n",
    "plt.subplot(1, 2, 2) # (rows, cols, index)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Model Loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Loss\", \"Validation Loss\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ds785)",
   "language": "python",
   "name": "ds785"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
