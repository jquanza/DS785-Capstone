{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "067c4865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf928d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic convolutional neural network\n",
    "import keras_tuner as kt\n",
    "from keras_tuner import BayesianOptimization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "import os, numpy as np, time\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49daa940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hms(start, end):\n",
    "    seconds = end-start\n",
    "    m, s = divmod(seconds, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return h,m,s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd5329b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hp):\n",
    "    \"\"\"\n",
    "    Compiles a model integrated with pretrained layers\n",
    "    \n",
    "    \"\"\"\n",
    "    learning_rate = hp.Choice('learning_rate', values = [0.000001, 0.00001, 0.0001], default = 0.000001)\n",
    "    dropout_rate = hp.Float('dropout', 0.2, 0.8, step=0.1)\n",
    "    neurons = hp.Choice('neurons', values = [256, 512, 1024, 2048], default = 256)\n",
    "    dense_layers = hp.Int('dense_layers', 0, 2, default = 0)\n",
    "    pooling = hp.Choice(\"global_pooling\", [\"flatten\", \"avg\"], default = 'flatten')\n",
    "        \n",
    "    # Pretrained convolutional layers are loaded using the Imagenet weights.\n",
    "    # Include_top is set to False, in order to exclude the model's fully-connected layers.\n",
    "    conv_base = ResNet50(include_top=False,\n",
    "                     weights='imagenet', \n",
    "                     input_shape=(224, 224, 3))\n",
    "    \n",
    "    # Layers in the convolutional base are switched from trainable to non-trainable\n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Create a new 'top' of the model (i.e. fully-connected layers).\n",
    "    # This is 'bootstrapping' a new top_model onto the pretrained layers.\n",
    "    top_model = conv_base.output\n",
    "    \n",
    "    # Choose top model pooling layer.\n",
    "    if pooling == \"avg\":\n",
    "        top_model = GlobalAveragePooling2D()(top_model)\n",
    "        for dl in range(dense_layers):\n",
    "            top_model = Dense(neurons, activation='relu')(top_model)\n",
    "            top_model = Dropout(dropout_rate)(top_model)\n",
    "    else:\n",
    "        top_model = Flatten(name=\"flatten\")(top_model)\n",
    "        for dl in range(dense_layers):\n",
    "            top_model = Dense(neurons, activation='relu')(top_model)\n",
    "            top_model = Dropout(dropout_rate)(top_model)\n",
    "    \n",
    "    # Add final softmax layer for predictions\n",
    "    output_layer = Dense(5, activation='softmax')(top_model)\n",
    "    \n",
    "    # Group the convolutional base and new fully-connected layers into a Model object.\n",
    "    model = Model(inputs=conv_base.input, outputs=output_layer)\n",
    "\n",
    "    # Compiles the model for training.\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                                 loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29a9e078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 35 Complete [00h 04m 07s]\n",
      "val_accuracy: 0.7875000238418579\n",
      "\n",
      "Best val_accuracy So Far: 0.8166666626930237\n",
      "Total elapsed time: 02h 58m 49s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "{'learning_rate': 0.0001, 'dropout': 0.2, 'neurons': 2048, 'dense_layers': 1, 'global_pooling': 'avg'}\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2048)         4196352     global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2048)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 5)            10245       dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 27,794,309\n",
      "Trainable params: 4,206,597\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Results summary\n",
      "Results in hp_models\\ResNet50\n",
      "Showing 35 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 2048\n",
      "dense_layers: 1\n",
      "global_pooling: avg\n",
      "Score: 0.8166666626930237\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 2048\n",
      "dense_layers: 1\n",
      "global_pooling: avg\n",
      "Score: 0.8166666626930237\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 2048\n",
      "dense_layers: 2\n",
      "global_pooling: avg\n",
      "Score: 0.8069444298744202\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 2048\n",
      "dense_layers: 1\n",
      "global_pooling: avg\n",
      "Score: 0.8013888597488403\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.4000000000000001\n",
      "neurons: 2048\n",
      "dense_layers: 1\n",
      "global_pooling: avg\n",
      "Score: 0.800000011920929\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 2048\n",
      "dense_layers: 1\n",
      "global_pooling: avg\n",
      "Score: 0.7986111044883728\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 2048\n",
      "dense_layers: 1\n",
      "global_pooling: avg\n",
      "Score: 0.7958333492279053\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 2048\n",
      "dense_layers: 1\n",
      "global_pooling: avg\n",
      "Score: 0.7944444417953491\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 2048\n",
      "dense_layers: 1\n",
      "global_pooling: avg\n",
      "Score: 0.7916666865348816\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 2048\n",
      "dense_layers: 1\n",
      "global_pooling: avg\n",
      "Score: 0.7902777791023254\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 2048\n",
      "dense_layers: 1\n",
      "global_pooling: avg\n",
      "Score: 0.7888888716697693\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.8000000000000003\n",
      "neurons: 2048\n",
      "dense_layers: 1\n",
      "global_pooling: flatten\n",
      "Score: 0.7875000238418579\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 2048\n",
      "dense_layers: 1\n",
      "global_pooling: avg\n",
      "Score: 0.7875000238418579\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 2048\n",
      "dense_layers: 1\n",
      "global_pooling: avg\n",
      "Score: 0.7875000238418579\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 2048\n",
      "dense_layers: 1\n",
      "global_pooling: avg\n",
      "Score: 0.7861111164093018\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.4000000000000001\n",
      "neurons: 512\n",
      "dense_layers: 1\n",
      "global_pooling: avg\n",
      "Score: 0.7833333611488342\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.6000000000000001\n",
      "neurons: 2048\n",
      "dense_layers: 1\n",
      "global_pooling: avg\n",
      "Score: 0.7791666388511658\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.4000000000000001\n",
      "neurons: 2048\n",
      "dense_layers: 1\n",
      "global_pooling: flatten\n",
      "Score: 0.7777777910232544\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 2048\n",
      "dense_layers: 2\n",
      "global_pooling: avg\n",
      "Score: 0.7749999761581421\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 256\n",
      "dense_layers: 1\n",
      "global_pooling: flatten\n",
      "Score: 0.7736111283302307\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 2048\n",
      "dense_layers: 1\n",
      "global_pooling: avg\n",
      "Score: 0.7722222208976746\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.8000000000000003\n",
      "neurons: 2048\n",
      "dense_layers: 1\n",
      "global_pooling: avg\n",
      "Score: 0.7708333134651184\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 2048\n",
      "dense_layers: 1\n",
      "global_pooling: avg\n",
      "Score: 0.7652778029441833\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 2048\n",
      "dense_layers: 1\n",
      "global_pooling: avg\n",
      "Score: 0.762499988079071\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 2048\n",
      "dense_layers: 1\n",
      "global_pooling: avg\n",
      "Score: 0.7611111402511597\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 2048\n",
      "dense_layers: 2\n",
      "global_pooling: flatten\n",
      "Score: 0.7597222328186035\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.8000000000000003\n",
      "neurons: 2048\n",
      "dense_layers: 0\n",
      "global_pooling: flatten\n",
      "Score: 0.7569444179534912\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.30000000000000004\n",
      "neurons: 2048\n",
      "dense_layers: 1\n",
      "global_pooling: avg\n",
      "Score: 0.7555555701255798\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.6000000000000001\n",
      "neurons: 2048\n",
      "dense_layers: 2\n",
      "global_pooling: avg\n",
      "Score: 0.7527777552604675\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.2\n",
      "neurons: 256\n",
      "dense_layers: 2\n",
      "global_pooling: avg\n",
      "Score: 0.7513889074325562\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.8000000000000003\n",
      "neurons: 256\n",
      "dense_layers: 2\n",
      "global_pooling: avg\n",
      "Score: 0.7152777910232544\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 1e-05\n",
      "dropout: 0.5000000000000001\n",
      "neurons: 512\n",
      "dense_layers: 1\n",
      "global_pooling: avg\n",
      "Score: 0.7013888955116272\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "dropout: 0.8000000000000003\n",
      "neurons: 256\n",
      "dense_layers: 0\n",
      "global_pooling: avg\n",
      "Score: 0.6833333373069763\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 1e-06\n",
      "dropout: 0.8000000000000003\n",
      "neurons: 256\n",
      "dense_layers: 1\n",
      "global_pooling: flatten\n",
      "Score: 0.5486111044883728\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 1e-06\n",
      "dropout: 0.2\n",
      "neurons: 2048\n",
      "dense_layers: 0\n",
      "global_pooling: avg\n",
      "Score: 0.2986111044883728\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "31/31 [==============================] - 19s 448ms/step - loss: 0.6984 - accuracy: 0.7515 - val_loss: 0.9320 - val_accuracy: 0.5917\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.93199, saving model to weights\\ResNet50.hp.weights.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jquan\\miniconda3\\envs\\ds785\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "31/31 [==============================] - 14s 378ms/step - loss: 0.2320 - accuracy: 0.9297 - val_loss: 0.8228 - val_accuracy: 0.6653\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.93199 to 0.82280, saving model to weights\\ResNet50.hp.weights.hdf5\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - 14s 378ms/step - loss: 0.1529 - accuracy: 0.9549 - val_loss: 0.8693 - val_accuracy: 0.6931\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.82280\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - 15s 379ms/step - loss: 0.1145 - accuracy: 0.9708 - val_loss: 0.7903 - val_accuracy: 0.7028\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.82280 to 0.79026, saving model to weights\\ResNet50.hp.weights.hdf5\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - 15s 378ms/step - loss: 0.1053 - accuracy: 0.9674 - val_loss: 0.7554 - val_accuracy: 0.7472\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.79026 to 0.75544, saving model to weights\\ResNet50.hp.weights.hdf5\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - 14s 377ms/step - loss: 0.0852 - accuracy: 0.9782 - val_loss: 0.7301 - val_accuracy: 0.7528\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.75544 to 0.73011, saving model to weights\\ResNet50.hp.weights.hdf5\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - 14s 377ms/step - loss: 0.0794 - accuracy: 0.9760 - val_loss: 0.7193 - val_accuracy: 0.7375\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.73011 to 0.71934, saving model to weights\\ResNet50.hp.weights.hdf5\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - 14s 378ms/step - loss: 0.0674 - accuracy: 0.9789 - val_loss: 0.7134 - val_accuracy: 0.7750\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.71934 to 0.71338, saving model to weights\\ResNet50.hp.weights.hdf5\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - 14s 377ms/step - loss: 0.0691 - accuracy: 0.9814 - val_loss: 0.7128 - val_accuracy: 0.7611\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.71338 to 0.71280, saving model to weights\\ResNet50.hp.weights.hdf5\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - 14s 378ms/step - loss: 0.0647 - accuracy: 0.9824 - val_loss: 0.6960 - val_accuracy: 0.7597\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.71280 to 0.69597, saving model to weights\\ResNet50.hp.weights.hdf5\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - 14s 374ms/step - loss: 0.0609 - accuracy: 0.9855 - val_loss: 0.7151 - val_accuracy: 0.7625\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.69597\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - 15s 380ms/step - loss: 0.0482 - accuracy: 0.9870 - val_loss: 0.6764 - val_accuracy: 0.7736\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.69597 to 0.67645, saving model to weights\\ResNet50.hp.weights.hdf5\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - 15s 378ms/step - loss: 0.0501 - accuracy: 0.9873 - val_loss: 0.7014 - val_accuracy: 0.7778\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.67645\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - 15s 374ms/step - loss: 0.0431 - accuracy: 0.9868 - val_loss: 0.7189 - val_accuracy: 0.7875\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.67645\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - 15s 377ms/step - loss: 0.0487 - accuracy: 0.9853 - val_loss: 0.6944 - val_accuracy: 0.7847\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.67645\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - 15s 378ms/step - loss: 0.0427 - accuracy: 0.9875 - val_loss: 0.7613 - val_accuracy: 0.7597\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.67645\n",
      "Epoch 17/50\n",
      "31/31 [==============================] - 15s 378ms/step - loss: 0.0350 - accuracy: 0.9904 - val_loss: 0.7050 - val_accuracy: 0.7944\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.67645\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - 15s 378ms/step - loss: 0.0373 - accuracy: 0.9892 - val_loss: 0.6975 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.67645\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - 15s 374ms/step - loss: 0.0385 - accuracy: 0.9904 - val_loss: 0.8767 - val_accuracy: 0.7681\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.67645\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - 15s 374ms/step - loss: 0.0367 - accuracy: 0.9900 - val_loss: 0.7163 - val_accuracy: 0.7736\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.67645\n",
      "Epoch 21/50\n",
      "31/31 [==============================] - 15s 378ms/step - loss: 0.0339 - accuracy: 0.9904 - val_loss: 0.7130 - val_accuracy: 0.7889\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.67645\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - 15s 378ms/step - loss: 0.0332 - accuracy: 0.9907 - val_loss: 0.7219 - val_accuracy: 0.7833\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.67645\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - 15s 378ms/step - loss: 0.0316 - accuracy: 0.9917 - val_loss: 0.7021 - val_accuracy: 0.7944\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.67645\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - 15s 378ms/step - loss: 0.0317 - accuracy: 0.9912 - val_loss: 0.7389 - val_accuracy: 0.7972\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.67645\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - 15s 377ms/step - loss: 0.0273 - accuracy: 0.9917 - val_loss: 0.7127 - val_accuracy: 0.7931\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.67645\n",
      "Epoch 26/50\n",
      "31/31 [==============================] - 15s 373ms/step - loss: 0.0337 - accuracy: 0.9892 - val_loss: 0.6614 - val_accuracy: 0.8014\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.67645 to 0.66144, saving model to weights\\ResNet50.hp.weights.hdf5\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - 14s 377ms/step - loss: 0.0334 - accuracy: 0.9907 - val_loss: 0.7271 - val_accuracy: 0.8056\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.66144\n",
      "Epoch 28/50\n",
      "31/31 [==============================] - 15s 378ms/step - loss: 0.0276 - accuracy: 0.9917 - val_loss: 0.6727 - val_accuracy: 0.8042\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.66144\n",
      "Epoch 29/50\n",
      "31/31 [==============================] - 15s 377ms/step - loss: 0.0249 - accuracy: 0.9926 - val_loss: 0.7315 - val_accuracy: 0.8153\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.66144\n",
      "Epoch 30/50\n",
      "31/31 [==============================] - 15s 381ms/step - loss: 0.0280 - accuracy: 0.9919 - val_loss: 0.7353 - val_accuracy: 0.7875\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.66144\n",
      "Epoch 31/50\n",
      "31/31 [==============================] - 15s 377ms/step - loss: 0.0277 - accuracy: 0.9917 - val_loss: 0.6622 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.66144\n",
      "Epoch 32/50\n",
      "31/31 [==============================] - 15s 377ms/step - loss: 0.0226 - accuracy: 0.9944 - val_loss: 0.6478 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.66144 to 0.64783, saving model to weights\\ResNet50.hp.weights.hdf5\n",
      "Epoch 33/50\n",
      "31/31 [==============================] - 14s 378ms/step - loss: 0.0280 - accuracy: 0.9897 - val_loss: 0.8871 - val_accuracy: 0.7903\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.64783\n",
      "Epoch 34/50\n",
      "31/31 [==============================] - 15s 374ms/step - loss: 0.0227 - accuracy: 0.9953 - val_loss: 0.8296 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.64783\n",
      "Epoch 35/50\n",
      "31/31 [==============================] - 15s 377ms/step - loss: 0.0240 - accuracy: 0.9924 - val_loss: 0.8336 - val_accuracy: 0.8042\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.64783\n",
      "Epoch 36/50\n",
      "31/31 [==============================] - 15s 382ms/step - loss: 0.0220 - accuracy: 0.9926 - val_loss: 0.8152 - val_accuracy: 0.7958\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.64783\n",
      "Epoch 37/50\n",
      "31/31 [==============================] - 15s 378ms/step - loss: 0.0249 - accuracy: 0.9926 - val_loss: 0.6532 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.64783\n",
      "Epoch 38/50\n",
      "31/31 [==============================] - 15s 379ms/step - loss: 0.0268 - accuracy: 0.9919 - val_loss: 0.7657 - val_accuracy: 0.7819\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.64783\n",
      "Epoch 39/50\n",
      "31/31 [==============================] - 15s 377ms/step - loss: 0.0180 - accuracy: 0.9958 - val_loss: 0.7909 - val_accuracy: 0.8153\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.64783\n",
      "Epoch 40/50\n",
      "31/31 [==============================] - 15s 378ms/step - loss: 0.0240 - accuracy: 0.9912 - val_loss: 0.7591 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.64783\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 15s 378ms/step - loss: 0.0242 - accuracy: 0.9936 - val_loss: 0.7102 - val_accuracy: 0.8222\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.64783\n",
      "Epoch 42/50\n",
      "31/31 [==============================] - 15s 378ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.6944 - val_accuracy: 0.8125\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.64783\n",
      "Epoch 43/50\n",
      "31/31 [==============================] - 15s 378ms/step - loss: 0.0170 - accuracy: 0.9953 - val_loss: 0.7989 - val_accuracy: 0.8028\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.64783\n",
      "Epoch 44/50\n",
      "31/31 [==============================] - 15s 378ms/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 0.8096 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.64783\n",
      "Epoch 45/50\n",
      "31/31 [==============================] - 15s 377ms/step - loss: 0.0149 - accuracy: 0.9966 - val_loss: 0.6307 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.64783 to 0.63069, saving model to weights\\ResNet50.hp.weights.hdf5\n",
      "Epoch 46/50\n",
      "31/31 [==============================] - 14s 379ms/step - loss: 0.0201 - accuracy: 0.9934 - val_loss: 0.6988 - val_accuracy: 0.8319\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.63069\n",
      "Epoch 47/50\n",
      "31/31 [==============================] - 15s 378ms/step - loss: 0.0181 - accuracy: 0.9936 - val_loss: 0.8334 - val_accuracy: 0.7819\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.63069\n",
      "Epoch 48/50\n",
      "31/31 [==============================] - 15s 378ms/step - loss: 0.0232 - accuracy: 0.9924 - val_loss: 0.8248 - val_accuracy: 0.8014\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.63069\n",
      "Epoch 49/50\n",
      "31/31 [==============================] - 15s 378ms/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 0.7781 - val_accuracy: 0.8111\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.63069\n",
      "Epoch 50/50\n",
      "31/31 [==============================] - 15s 378ms/step - loss: 0.0177 - accuracy: 0.9949 - val_loss: 0.7724 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.63069\n",
      "Best ResNet50 Model Accuracy: 97.42%\n",
      "Average prediction time per image: 0.016639105280240377 seconds\n",
      "\n",
      "Total runtime is 3 hours, 11 minutes, 51.0 seconds\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = 'cropped_resized_imgs/train'\n",
    "test_data_dir = 'cropped_resized_imgs/test'\n",
    "class_subset = sorted(os.listdir(train_data_dir))\n",
    "\n",
    "img_size = 224\n",
    "BATCH_SIZE = 128\n",
    "totalstart = time.time()\n",
    "modelName = 'ResNet50'\n",
    "filename = 'ResNet50_HP_Tuning_Results.txt'\n",
    "\n",
    "# create image generators with data augmentation\n",
    "train_generator = ImageDataGenerator(\n",
    "    width_shift_range=0.5,       # shift the width of the image 50%\n",
    "    rotation_range=90,           # random rotation by 90 degrees\n",
    "    horizontal_flip=True,        # 180 degree flip horizontally\n",
    "    vertical_flip=True,          # 180 degree flip vertically\n",
    "    validation_split=0.15,       # 15% of the data will be used for validation at end of each epoch\n",
    "    preprocessing_function=preprocess_input # VGG16 preprocessing\n",
    ")\n",
    "\n",
    "traingen = train_generator.flow_from_directory(train_data_dir,\n",
    "                                                target_size=(img_size, img_size),\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                class_mode='categorical',\n",
    "                                                classes=class_subset,\n",
    "                                                subset='training',\n",
    "                                                shuffle=True,\n",
    "                                                seed=55)\n",
    "\n",
    "validgen = train_generator.flow_from_directory(train_data_dir,\n",
    "                                                target_size=(img_size, img_size),\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                class_mode='categorical',\n",
    "                                                classes=class_subset,\n",
    "                                                subset='validation',\n",
    "                                                shuffle=True,\n",
    "                                                seed=55)\n",
    "\n",
    "test_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "testgen = test_generator.flow_from_directory(test_data_dir,\n",
    "                                             target_size=(img_size, img_size),\n",
    "                                             batch_size=1,\n",
    "                                             class_mode=None,\n",
    "                                             shuffle=False,\n",
    "                                             seed=55)\n",
    "# set values\n",
    "n_epochs = 50\n",
    "max_trial_epochs = 40\n",
    "max_trials = 35\n",
    "n_steps = traingen.samples / BATCH_SIZE\n",
    "n_val_steps = validgen.samples / BATCH_SIZE\n",
    "\n",
    "tuner = BayesianOptimization(create_model,\n",
    "                objective='val_accuracy',\n",
    "                max_trials=max_trials,\n",
    "                directory='hp_models',\n",
    "                project_name=modelName,\n",
    "                overwrite=True,\n",
    "                seed=55)\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           patience=5,\n",
    "                           restore_best_weights=True,\n",
    "                           mode='min')\n",
    "\n",
    "tuner.search(traingen,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            epochs=max_trial_epochs,\n",
    "            validation_data=validgen,\n",
    "            steps_per_epoch=n_steps,\n",
    "            validation_steps=n_val_steps,\n",
    "            callbacks=[early_stop],\n",
    "            workers=16,\n",
    "            verbose=1)\n",
    "\n",
    "# print and save tuner results\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "print(best_hp.values)\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)\n",
    "print(best_model[0].summary())\n",
    "\n",
    "print(tuner.results_summary(num_trials=max_trials))\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "    f.write('Best hyperparameters: {}\\n\\nBest Model Summary\\n'.format(best_hp.values))\n",
    "    best_model[0].summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "\n",
    "# ************************************************************************************************************\n",
    "# train full model with hyperparameters\n",
    "\n",
    "# ModelCheckpoint callback - save best weights\n",
    "tl_checkpoint_1 = ModelCheckpoint(filepath='weights/{}.hp.weights.hdf5'.format(modelName),\n",
    "                                  save_best_only=True,\n",
    "                                  verbose=1)\n",
    "\n",
    "# load and train model from hyperparameters\n",
    "bestTunedModel = tuner.hypermodel.build(best_hp)\n",
    "history = bestTunedModel.fit(traingen,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=n_epochs,\n",
    "                    validation_data=validgen,\n",
    "                    steps_per_epoch=n_steps,\n",
    "                    validation_steps=n_val_steps,\n",
    "                    callbacks=[tl_checkpoint_1],\n",
    "                    workers=16,\n",
    "                    verbose=1)\n",
    "\n",
    "# load model weights\n",
    "bestTunedModel.load_weights('weights/{}.hp.weights.hdf5'.format(modelName)) # initialize the best trained weights\n",
    "# get labels\n",
    "labels = traingen.class_indices\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "\n",
    "# Generate predictions\n",
    "testgen.reset()\n",
    "predstart = time.time()\n",
    "preds = bestTunedModel.predict(testgen)\n",
    "pred_classes = np.argmax(preds, axis=1)\n",
    "true_classes = testgen.classes\n",
    "acc = accuracy_score(true_classes, pred_classes)\n",
    "predend = time.time()\n",
    "avgPredictionTime = (predend - predstart)/1200\n",
    "\n",
    "print(\"Best {} Model Accuracy: {:.2f}%\".format(modelName, acc * 100))\n",
    "\n",
    "# save history object to disk\n",
    "with open('modelrun_history/{}.hp.history'.format(modelName), 'wb') as histfile:\n",
    "    pickle.dump(history.history, histfile)\n",
    "\n",
    "# save model accuracy to file\n",
    "with open(filename, 'a') as f:\n",
    "    f.write(\"{} Model Accuracy: {:.2f}%\\n\".format(modelName, acc * 100))\n",
    "    f.write(\"Average prediction time per image: {} seconds\\n\".format(avgPredictionTime))\n",
    "\n",
    "# total modeling time\n",
    "totalEnd = time.time()\n",
    "totalT=hms(totalstart, totalEnd)\n",
    "print(\"Average prediction time per image: {} seconds\\n\".format(avgPredictionTime))\n",
    "print('Total runtime is {:.0f} hours, {:.0f} minutes, {:.1f} seconds'.format(totalT[0],totalT[1],totalT[2]))\n",
    "with open(filename, 'a') as f:\n",
    "    f.write('Total runtime is {:.0f} hours, {:.0f} minutes, {:.1f} seconds'.format(totalT[0],totalT[1],totalT[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b8d9380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x155d475ae80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training/validation accuracy and loss\n",
    "plt.figure(figsize=(12, 6)) # figsize(width, height) in inches, dpi=100\n",
    "# plot accuracy\n",
    "plt.subplot(1, 2, 1) # (rows, cols, index)\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\", \"Validation Accuracy\"])\n",
    "\n",
    "plt.subplot(1, 2, 2) # (rows, cols, index)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Model Loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Loss\", \"Validation Loss\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ds785)",
   "language": "python",
   "name": "ds785"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
