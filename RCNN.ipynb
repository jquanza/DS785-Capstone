{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "329814b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "#from keras.applications import ResNet50\n",
    "#from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "#from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import imutils\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d054f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, step, ws):\n",
    "    # slide a window across the image\n",
    "    for y in range(0, image.shape[0] - ws[1], step):\n",
    "        for x in range(0, image.shape[1] - ws[0], step):\n",
    "            # yield the current window\n",
    "            yield (x, y, image[y:y + ws[1], x:x + ws[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "680a1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_pyramid(image, scale=1.5, minSize=(224, 224)):\n",
    "    # yield the original image\n",
    "    yield image\n",
    "    # keep looping over the image pyramid\n",
    "    while True:\n",
    "        # compute the dimensions of the next image in the pyramid\n",
    "        w = int(image.shape[1] / scale)\n",
    "        image = imutils.resize(image, width=w)\n",
    "        # if the resized image does not meet the supplied minimum\n",
    "        # size, then stop constructing the pyramid\n",
    "        if image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\n",
    "            break\n",
    "        # yield the next image in the pyramid\n",
    "        yield image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d11d7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables used for the object detection procedure\n",
    "WIDTH = 300\n",
    "PYR_SCALE = 1.5\n",
    "WIN_STEP = 16\n",
    "ROI_SIZE = (150, 150)\n",
    "INPUT_SIZE = (224, 224)\n",
    "min_conf = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93489c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading network...\n"
     ]
    }
   ],
   "source": [
    "# load our network weights from disk\n",
    "label = 'cirsium setosum'\n",
    "impath = r'C:\\Users\\jrsquan\\Desktop\\DS785\\weed-datasets-master\\{}.jpg'.format(label)\n",
    "imbeforepath = r'C:\\Users\\jrsquan\\Desktop\\DS785\\weed-datasets-master\\{} before.jpg'.format(label)\n",
    "imafterpath = r'C:\\Users\\jrsquan\\Desktop\\DS785\\weed-datasets-master\\{} after.jpg'.format(label)\n",
    "\n",
    "print(\"[INFO] loading network...\")\n",
    "model = load_model('weights/ResNet50.hp.weights.hdf5')\n",
    "#model = load_model('weights/EfficientNetB0.hp.weights.hdf5')\n",
    "\n",
    "# load the input image from disk, resize it such that it has the\n",
    "# has the supplied width, and then grab its dimensions\n",
    "orig = cv2.imread(impath)\n",
    "orig = imutils.resize(orig, width=WIDTH)\n",
    "(H, W) = orig.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3192204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the image pyramid\n",
    "pyramid = image_pyramid(orig, scale=PYR_SCALE, minSize=ROI_SIZE)\n",
    "# initialize two lists, one to hold the ROIs generated from the image\n",
    "# pyramid and sliding window, and another list used to store the\n",
    "# (x, y)-coordinates of where the ROI was in the original image\n",
    "rois = []\n",
    "locs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "806f8d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] looping over pyramid/windows took 0.06194 seconds\n",
      "[INFO] classifying ROIs...\n",
      "[INFO] classifying ROIs took 6.95786 seconds\n"
     ]
    }
   ],
   "source": [
    "# time how long it takes to loop over the image pyramid layers and\n",
    "# sliding window locations\n",
    "start = time.time()\n",
    "\n",
    "# loop over the image pyramid\n",
    "for image in pyramid:\n",
    "    # determine the scale factor between the *original* image\n",
    "    # dimensions and the *current* layer of the pyramid\n",
    "    scale = W / float(image.shape[1])\n",
    "    # for each layer of the image pyramid, loop over the sliding\n",
    "    # window locations\n",
    "    for (x, y, roiOrig) in sliding_window(image, WIN_STEP, ROI_SIZE):\n",
    "        # scale the (x, y)-coordinates of the ROI with respect to the\n",
    "        # *original* image dimensions\n",
    "        x = int(x * scale)\n",
    "        y = int(y * scale)\n",
    "        w = int(ROI_SIZE[0] * scale)\n",
    "        h = int(ROI_SIZE[1] * scale)\n",
    "        # take the ROI and preprocess it so we can later classify\n",
    "        # the region using Keras/TensorFlow\n",
    "        roi = cv2.resize(roiOrig, INPUT_SIZE)\n",
    "        roi = img_to_array(roi)\n",
    "        roi = preprocess_input(roi)\n",
    "        # update our list of ROIs and associated coordinates\n",
    "        rois.append(roi)\n",
    "        locs.append((x, y, x + w, y + h))\n",
    "            \n",
    "# show how long it took to loop over the image pyramid layers and\n",
    "# sliding window locations\n",
    "end = time.time()\n",
    "print(\"[INFO] looping over pyramid/windows took {:.5f} seconds\".format(end - start))\n",
    "# convert the ROIs to a NumPy array\n",
    "rois = np.array(rois, dtype=\"float32\")\n",
    "# classify each of the proposal ROIs using ResNet and then show how\n",
    "# long the classifications took\n",
    "print(\"[INFO] classifying ROIs...\")\n",
    "start = time.time()\n",
    "preds = model.predict(rois)\n",
    "end = time.time()\n",
    "print(\"[INFO] classifying ROIs took {:.5f} seconds\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56977fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_classes = np.argmax(preds, axis=1)\n",
    "counts = np.bincount(pred_classes)\n",
    "mostFreqClass = np.argmax(counts)\n",
    "classes = {0: 'bluegrass', 1: 'chenopodium album', 2: 'cirsium setosum', 3: 'corn', 4: 'sedge'}\n",
    "class_list = [classes[x] for x in pred_classes]\n",
    "pred_val = np.amax(preds, axis=1)\n",
    "preds1 = list(zip(class_list, pred_val))\n",
    "#print(preds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97dbbf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode the predictions and initialize a dictionary which maps class\n",
    "# labels (keys) to any ROIs associated with that label (values)\n",
    "#preds = imagenet_utils.decode_predictions(preds, top=1)\n",
    "\n",
    "labels = {}\n",
    "# loop over the predictions\n",
    "for (i, p) in enumerate(preds1):\n",
    "    # grab the prediction information for the current ROI\n",
    "    #(imagenetID, label, prob) = p[0]\n",
    "    (label, prob) = p\n",
    "    # filter out weak detections by ensuring the predicted probability\n",
    "    # is greater than the minimum probability\n",
    "    if label == classes[mostFreqClass]:\n",
    "        if prob >= min_conf:\n",
    "            # grab the bounding box associated with the prediction and\n",
    "            # convert the coordinates\n",
    "            box = locs[i]\n",
    "            # grab the list of predictions for the label and add the\n",
    "            # bounding box and probability to the list\n",
    "            L = labels.get(label, [])\n",
    "            L.append((box, prob))\n",
    "            labels[label] = L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "828f6999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] showing results for 'cirsium setosum'\n"
     ]
    }
   ],
   "source": [
    "# loop over the labels for each of detected objects in the image\n",
    "for label in labels.keys():\n",
    "    # clone the original image so that we can draw on it\n",
    "    print(\"[INFO] showing results for '{}'\".format(label))\n",
    "    clone = orig.copy()\n",
    "    # loop over all bounding boxes for the current label\n",
    "    for (box, prob) in labels[label]:\n",
    "        # draw the bounding box on the image\n",
    "        (startX, startY, endX, endY) = box\n",
    "        cv2.rectangle(clone, (startX, startY), (endX, endY),\n",
    "            (0, 255, 0), 2)\n",
    "    # show the results *before* applying non-maxima suppression, then\n",
    "    # clone the image again so we can display the results *after*\n",
    "    # applying non-maxima suppression\n",
    "    \n",
    "    #cv2.imshow(\"Before\", clone)\n",
    "    cv2.imwrite(imbeforepath, clone)\n",
    "    clone = orig.copy()\n",
    "    # extract the bounding boxes and associated prediction\n",
    "    # probabilities, then apply non-maxima suppression\n",
    "    boxes = np.array([p[0] for p in labels[label]])\n",
    "    proba = np.array([p[1] for p in labels[label]])\n",
    "    boxes = non_max_suppression(boxes, proba)\n",
    "    # loop over all bounding boxes that were kept after applying\n",
    "    # non-maxima suppression\n",
    "    for (startX, startY, endX, endY) in boxes:\n",
    "        # draw the bounding box and label on the image\n",
    "        cv2.rectangle(clone, (startX, startY), (endX, endY),\n",
    "            (0, 255, 0), 2)\n",
    "        y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "        cv2.putText(clone, label, (startX, y),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
    "    # show the output after apply non-maxima suppression\n",
    "    #cv2.imshow(\"After\", clone)\n",
    "    cv2.imwrite(imafterpath, clone)\n",
    "    #cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0d8bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ds785)",
   "language": "python",
   "name": "ds785"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
